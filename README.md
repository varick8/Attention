# Attention
This repository contains a complete implementation of a GPT-style Transformer model built from scratch using only NumPy, as part of an individual assignment to understand the core architecture of Transformers.
